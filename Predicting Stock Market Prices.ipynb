{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Stock Market Prices Using HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GATHERING AND CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm, pyplot as plt\n",
    "import seaborn\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator\n",
    "import pandas as pd\n",
    "import numpy \n",
    "from datetime import datetime\n",
    "\n",
    "def get_stock_data(file_name):\n",
    "    \"\"\"scrapes and cleans the data from the given file and creates a dataframe\n",
    "    \n",
    "    Args:\n",
    "        file_name (string) : name of file\n",
    "    \n",
    "    Returns:\n",
    "        df_stock (dataframe) : dataframe containing stock info scraped from file\n",
    "    \"\"\"\n",
    "    df_stock = pd.DataFrame()\n",
    "    file = open(file_name)\n",
    "    txt = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    # split text into list, split by new line character\n",
    "    txt = txt.split('\\n')\n",
    "    # get column titles\n",
    "    columns = txt[0].split(',')\n",
    "\n",
    "    for line in txt[1:]:\n",
    "        temp_dict = dict()\n",
    "        line = line.strip()\n",
    "        line_list = line.split(',')\n",
    "\n",
    "        # if row does not have sufficient column information, pass over\n",
    "        if len(columns) != len(line_list):\n",
    "            continue\n",
    "\n",
    "        # add column's corresponding values to a temporary dictionary   \n",
    "        for idx in range(len(columns)):\n",
    "            column_name = columns[idx]\n",
    "            \n",
    "            # change all date column info to datetime object\n",
    "            if column_name == 'Date':\n",
    "                temp_dict[column_name] = datetime.strptime(line_list[idx], '%Y-%m-%d')\n",
    "            else:\n",
    "                temp_dict[column_name] = line_list[idx]\n",
    "\n",
    "        # append dictionary to dataframe                                                  \n",
    "        df_stock = df_stock.append(temp_dict, ignore_index=True)\n",
    "    \n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>OpenInt</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>33.754</td>\n",
       "      <td>27.002</td>\n",
       "      <td>30.713</td>\n",
       "      <td>0</td>\n",
       "      <td>66277506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.257</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>29.027</td>\n",
       "      <td>26.872</td>\n",
       "      <td>28.986</td>\n",
       "      <td>0</td>\n",
       "      <td>16142920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.044</td>\n",
       "      <td>27.886</td>\n",
       "      <td>0</td>\n",
       "      <td>6970266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.002</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>29.446</td>\n",
       "      <td>27.002</td>\n",
       "      <td>28.688</td>\n",
       "      <td>0</td>\n",
       "      <td>6332082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.717</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.309</td>\n",
       "      <td>27.002</td>\n",
       "      <td>27.083</td>\n",
       "      <td>0</td>\n",
       "      <td>5132147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.807</td>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>28.012</td>\n",
       "      <td>27.509</td>\n",
       "      <td>27.594</td>\n",
       "      <td>0</td>\n",
       "      <td>1832635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Close       Date    High     Low    Open OpenInt    Volume\n",
       "0  29.702 1999-11-18  33.754  27.002  30.713       0  66277506\n",
       "1  27.257 1999-11-19  29.027  26.872  28.986       0  16142920\n",
       "2  29.702 1999-11-22  29.702  27.044  27.886       0   6970266\n",
       "3  27.002 1999-11-23  29.446  27.002  28.688       0   6332082\n",
       "4  27.717 1999-11-24  28.309  27.002  27.083       0   5132147\n",
       "5  27.807 1999-11-26  28.012  27.509  27.594       0   1832635"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'a.us.txt'\n",
    "df_a_stock = get_stock_data(file_name)\n",
    "\n",
    "test_df = df_a_stock.head(6)\n",
    "test_df\n",
    "#df_a_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_stock_files = ['a.us.txt', 'abc.us.txt', 'aktx.us.txt', 'blue.us.txt', 'bro.us.txt', 'by.us.txt',\n",
    "                    'casi.us.txt', 'cbu.us.txt', 'cxdc.us.txt', 'dhr.us.txt', 'dxyn.us.txt', 'ebay.us.txt',\n",
    "                    'eei.us.txt', 'eod.us.txt', 'fox.us.txt', 'ftrpr.us.txt', 'fwonk.us.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission(stock_dataframe):\n",
    "    \"\"\" Calculates the one day difference between stock closing value (today - yesterday)\n",
    "        and determines emission symbol based on if stock price increased or decreased from previous day\n",
    "    \n",
    "    Args:\n",
    "        stock_dataframe (dataframe) : dataframe containing stock info(close value, date, high, low, open, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        one_day_dif_df(dataframe) : dataframe containing the difference from the previous day's stock value\n",
    "                                    as well as the related emission symbol (Increasing or Decreasing)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset the initial DF to obtain only relevant columns\n",
    "    one_day_dif_df = stock_dataframe.copy()\n",
    "    one_day_dif_df = one_day_dif_df[['Date','Close']]\n",
    "    \n",
    "    # Convert CV to numeric for calculations\n",
    "    one_day_dif_df['Close'] = pd.to_numeric(one_day_dif_df['Close'])\n",
    "    one_day_dif_df['Yesterday Close'] = one_day_dif_df['Close'].shift()\n",
    "    \n",
    "    # Calculate the stock's closing price difference from the previous day\n",
    "    one_day_dif_df['Close Value Difference'] = round((one_day_dif_df['Close'] - one_day_dif_df['Yesterday Close']),2)\n",
    "    \n",
    "    one_day_dif_df['Emission'] = 'NaN'\n",
    "    row_indexes_inc = one_day_dif_df[one_day_dif_df['Close Value Difference']>=0].index\n",
    "    row_indexes_dec = one_day_dif_df[one_day_dif_df['Close Value Difference']<0].index\n",
    "    \n",
    "    one_day_dif_df.loc[row_indexes_inc,'Emission']='Increasing'\n",
    "    one_day_dif_df.loc[row_indexes_dec,'Emission']='Decreasing'\n",
    "    #one_day_dif_df['Emission'] = ['Increasing' if x > 0 else 'Decreasing' for x in one_day_dif_df['Close Value Difference']]\n",
    "    \n",
    "    return one_day_dif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN\n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing\n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing\n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing\n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing\n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emission = get_emission(test_df)\n",
    "df_emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMP AND TMP MATRIX INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TPM(n):\n",
    "    \"\"\"creates transition probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        \n",
    "    Returns:\n",
    "        tpm (array of arrays) : n by n transition probability matrix\n",
    "                                    s1 s2 s3 s4 s5 s6\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    tpm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / n, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(n):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        tpm.append(row)\n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = create_TPM(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_EPM(n, m):\n",
    "    \"\"\"creates emissions probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        m (int) : number of possible observation symbols\n",
    "        \n",
    "    Returns:\n",
    "        epm (array of arrays) : n by m emission probability matrix\n",
    "                                    I  D\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    \n",
    "    epm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / m, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(m):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        epm.append(row)\n",
    "        \n",
    "    return epm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epm = create_EPM(6, 2)\n",
    "epm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD BACKWARD ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Forward Backward Algorithm: the probability of an observation sequence occurring given the model. \n",
    "\n",
    "- Forward: probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "- Backward: probability that we will see a certain sequence of future observations, given we are in a certain state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Initialization visualization: \n",
    "        S1 S2 S3 S4 S5 S6\n",
    "    T1  .2 .1 .1 .2 .1 .1  (PI)\n",
    "        * EPM - probability of emitting whatever our first observation is \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    alpha = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            if OBSERVATIONS[T] == \"Increasing\":\n",
    "                row.append(pi[N] * epm[N][0])\n",
    "            if OBSERVATIONS[T] == \"Decreasing\":\n",
    "                row.append(pi[N] * epm[N][1])\n",
    "            \n",
    "        alpha.append(row)\n",
    "\n",
    "    # for each time step from 2 to T\n",
    "    for time in range(1, len(OBSERVATIONS)):\n",
    "        curr_time_idx = time\n",
    "        prev_time_idx = curr_time_idx - 1\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            prev_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each previous state through all possible paths \n",
    "                a = alpha[prev_time_idx][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][state]\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[state][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[state][1]\n",
    "                    \n",
    "                prev_paths_sum += a * b * c\n",
    "\n",
    "            alpha[curr_time_idx][state] = prev_paths_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = [[0.2, 0.1, 0.3, 0.1, 0.2, 0.1],\n",
    "       [0.3, 0.1, 0.1, 0.2, 0.3, 0],\n",
    "       [0.1, 0.1, 0.1, 0.3, 0.2, 0.2],\n",
    "       [0.4, 0.1, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.3, 0.2, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.1, 0.1, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.05, 0.05, 0.1, 0.05, 0.05]\n",
      "[0.052500000000000005, 0.025000000000000005, 0.0325, 0.027500000000000004, 0.03250000000000001, 0.030000000000000006]\n",
      "[0.024, 0.013125000000000003, 0.01675, 0.014500000000000006, 0.016750000000000004, 0.014875000000000003]\n",
      "[0.012106250000000004, 0.006581250000000001, 0.00814375, 0.007331250000000001, 0.008350000000000003, 0.007487500000000001]\n",
      "[0.0060725000000000015, 0.003291875000000001, 0.004085000000000001, 0.003643437500000001, 0.004170625000000002, 0.003736562500000001]\n"
     ]
    }
   ],
   "source": [
    "emissions = [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "pi = [.2, .1, .1, .2, .1, .1]\n",
    "frd = forward(tpm, epm, pi, emissions)\n",
    "for observation in frd:\n",
    "    print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_test(V, a, b, pi):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        V : emission matrix\n",
    "        a : tpm\n",
    "        b : epm\n",
    "        pi : initial distribution\n",
    "    \n",
    "    Returns:\n",
    "        alpha\n",
    "        \n",
    "    Citation:\n",
    "        https://datascience.stackexchange.com/questions/74126/hidden-markov-model-forward-algorithm-implementation-in-python\n",
    "    \"\"\"\n",
    "    alpha = np.zeros((len(V), len(a)))\n",
    "    \n",
    "    # alpha[0, :] = pi * b[:, V[0]]\n",
    "    for state in range(len(alpha[0])):\n",
    "        if V[0] == \"Increasing\":\n",
    "                ob = epm[state][0]\n",
    "        if V[0] == \"Decreasing\":\n",
    "                ob = epm[state][1]\n",
    "                \n",
    "        alpha[0][state] = pi[state] * ob  \n",
    "    \n",
    "    # for each observation, 1 to T\n",
    "    for t in range(1, len(V)):\n",
    "        # for each state\n",
    "        for j in range(len(a)):\n",
    "            \n",
    "            prev_state_sum = 0\n",
    "            # for each state\n",
    "            for s_prime in range(len(a)):\n",
    "                \n",
    "                if V[t] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                prev_state_sum += alpha[t - 1][s_prime] * a[s_prime][j] * b[j][idx]\n",
    "            \n",
    "            alpha[t][j] = prev_state_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.05 0.05 0.1  0.05 0.05]\n",
      "[0.0525 0.025  0.0325 0.0275 0.0325 0.03  ]\n",
      "[0.024    0.013125 0.01675  0.0145   0.01675  0.014875]\n",
      "[0.01210625 0.00658125 0.00814375 0.00733125 0.00835    0.0074875 ]\n",
      "[0.0060725  0.00329188 0.004085   0.00364344 0.00417063 0.00373656]\n"
     ]
    }
   ],
   "source": [
    "frd_test = forward_test(emissions, tpm, epm, pi)\n",
    "\n",
    "for state in frd_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(frd)):\n",
    "    for state in range(len(frd[observation])):\n",
    "        # print(frd_test[observation][state], frd[observation][state])\n",
    "        assert frd_test[observation][state] == frd[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we will see a certain sequence of future observations, given we are in a certain state\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        backwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    beta = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            row.append(1.0)\n",
    "        \n",
    "        beta.append(row)\n",
    "    \n",
    "    # recursion\n",
    "    # for each time step from T-1 to 1 (end is exclusive)\n",
    "    for time in range(len(OBSERVATIONS) - 2, -1, -1):\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            next_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each next state through all possible paths \n",
    "                a = beta[time+1][s_prime]\n",
    "                \n",
    "                # the transition probability from next S to current S\n",
    "                b = tpm[state][s_prime]\n",
    "                \n",
    "                # the emission probability of emitting observation at next S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[s_prime][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[s_prime][1]\n",
    "                    \n",
    "                next_paths_sum += a * b *c\n",
    "\n",
    "            beta[time][state] = next_paths_sum\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06250000000000001, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125]\n",
      "[0.25000000000000006, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "[0.5000000000000001, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "back = backward(tpm, epm, pi, emissions)\n",
    "for state in back:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_test(observations, trans, emis, numstates):\n",
    "    backwardmatrix = numpy.zeros((len(observations), numstates))\n",
    "\n",
    "    # initialization\n",
    "    for s in range(numstates):\n",
    "        backwardmatrix[len(observations) - 1][s] = 1.0\n",
    "\n",
    "    # recursion\n",
    "    for t in range(len(observations) - 2, -1, -1):\n",
    "        \n",
    "        if observations[t] == \"Increasing\":\n",
    "            obs_index = 0\n",
    "        if observations[t] == \"Decreasing\":\n",
    "            obs_index = 1\n",
    "        \n",
    "        for s in range(numstates):\n",
    "            \n",
    "            for s2 in range(numstates):\n",
    "                backwardmatrix[t][s] += trans[s][s2] * emis[s2][obs_index] * backwardmatrix[t+1][s2]\n",
    "\n",
    "    return backwardmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "[0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "back_test = backward_test(emissions, tpm, epm, 6)\n",
    "\n",
    "for state in back_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(emissions)):\n",
    "    for state in range(len(back[observation])):\n",
    "        # print(back_test[observation][state], back[observation][state])\n",
    "        assert back_test[observation][state] == back[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frwd_backwd(tpm, epm, init, observations):\n",
    "    \"\"\"the probability of an observation sequence occurring given the model\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        init () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd_backwd (int) : probability of an observation sequence occurring\n",
    "    \"\"\"\n",
    "    frwd = forward(tpm, epm, pi, observations)\n",
    "    bkwd = backward(tpm, epm, pi, observations)\n",
    "\n",
    "    # matrix multiplication\n",
    "    result = [[sum(frwd*bkwd for frwd,bkwd in zip(X_row,Y_col)) for Y_col in zip(*bkwd)] for X_row in frwd]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
       " [0.060781250000000016,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001],\n",
       " [0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001],\n",
       " [0.015630859375000007,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004],\n",
       " [0.007804609375000004,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frwd_backwd(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAUM WELCH ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, determine the parameters of the HMM that generated that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frwd = forward(tpm, epm, pi, emissions)\n",
    "bkwd = backward(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convergence(old_matrix, new_matrix):\n",
    "    \"\"\"returns true if matricies have converged (aka are the same), false otherwise\n",
    "    \n",
    "    Args:\n",
    "        old_matrix (array of arrays) : old matrix\n",
    "        new_matrix (array of arrays) : new matrix\n",
    "        \n",
    "    Returns:\n",
    "        converge (boolean) : represents whether the given matricies have converged or not\n",
    "        \n",
    "    \"\"\"\n",
    "    converge = True\n",
    "    for col in range(len(old_matrix)):\n",
    "        for row in range(len(old_matrix[col])):\n",
    "            if old_matrix[col][row] != new_matrix[col][row]:\n",
    "                converge = False\n",
    "    \n",
    "    return converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test check_covergence()\n",
    "\n",
    "old_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "new_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new_matrix) == True, \"method claims matricies have not converged\"\n",
    "\n",
    "new2_matrix = [[1, 2], [2, 2], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new2_matrix) == False, \"method claims matricies have converged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(tpm, epm, pi, emissions):\n",
    "    \"\"\"probability of initial parameters that generated emissions data\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # transition probabilities\n",
    "    A = np.zeros((6, 6))\n",
    "    # observation probabilities\n",
    "    B = np.ones((len(emissions) + 1, 2))\n",
    "    \n",
    "    # xi dictionary\n",
    "    xi = dict()\n",
    "    # gamma dictionary\n",
    "    gamma = dict()\n",
    "    \n",
    "    # iterate until convergence\n",
    "    # while (check_convergence(tpm, A) == False and check_convergence(epm, B) == False):\n",
    "    \n",
    "    # HOW CHECK CONVERGENCE? JUST RUN 10 TIMES\n",
    "    for i in range(10):\n",
    "        \n",
    "        # E STEP\n",
    "\n",
    "        for time in range(len(emissions)):\n",
    "    \n",
    "             # get normalization constant for time P(O|HMM)\n",
    "            normalization_const = 0\n",
    "            for state in range(6):\n",
    "                normalization_const += frwd[time][state] * bkwd[time][state]\n",
    "\n",
    "            for state_i in range(6):\n",
    "                # update gamma values for (time, state_i) in gamma dictionary\n",
    "                gamma[(time, state_i)] = (frwd[time][state_i] * bkwd[time][state_i]) / normalization_const\n",
    "\n",
    "        for time in range(len(emissions) - 1):\n",
    "\n",
    "                # get emissions index\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if emissions[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "\n",
    "                for state_i in range(6):\n",
    "\n",
    "                    for state_j in range(6):\n",
    "\n",
    "                        # update xi values for (time, state_i, state_j) in xi dictionary\n",
    "                        temp_xi = frwd[time][state_j] * tpm[state_i][state_j] * epm[state_j][idx] * bkwd[time + 1][state_j]\n",
    "                        xi[(time, state_i, state_j)] = temp_xi / normalization_const\n",
    "        \n",
    "        # M STEP\n",
    "        \n",
    "        # update alpha\n",
    "        for state_i in range(6):\n",
    "            for state_j in range(6):\n",
    "\n",
    "                nominator_sum = 0\n",
    "                denom_sum = 0\n",
    "\n",
    "                for time in range(1, len(emissions) - 1):\n",
    "                    nominator_sum += xi[(time, state_i, state_j)]\n",
    "\n",
    "                    temp_sum = 0\n",
    "                    for state_prime in range(6):\n",
    "                        temp_sum += xi[(time, state_i, state_prime)]\n",
    "\n",
    "                    denom_sum += temp_sum\n",
    "\n",
    "                A[state_i][state_j] = nominator_sum / denom_sum\n",
    "\n",
    "        # update beta\n",
    "\n",
    "        increasing_idx = 0     # tracked observation variable\n",
    "        for state in range(6):\n",
    "\n",
    "            numerator = 0\n",
    "            denom = 0\n",
    "\n",
    "            for time in range(len(emissions)):\n",
    "\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    numerator += gamma[(time, state)]\n",
    "\n",
    "                denom += gamma[(time, state)]\n",
    "\n",
    "                B[state][increasing_idx] = numerator / denom\n",
    "                B[state][1] = 1 - (numerator / denom)\n",
    "    for item in gamma:\n",
    "        print(item, gamma[item])\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0.25000000000000006\n",
      "(0, 1) 0.125\n",
      "(0, 2) 0.125\n",
      "(0, 3) 0.25\n",
      "(0, 4) 0.125\n",
      "(0, 5) 0.125\n",
      "(1, 0) 0.26250000000000007\n",
      "(1, 1) 0.125\n",
      "(1, 2) 0.16249999999999998\n",
      "(1, 3) 0.13749999999999998\n",
      "(1, 4) 0.1625\n",
      "(1, 5) 0.15\n",
      "(2, 0) 0.24000000000000002\n",
      "(2, 1) 0.13125\n",
      "(2, 2) 0.16749999999999998\n",
      "(2, 3) 0.14500000000000002\n",
      "(2, 4) 0.1675\n",
      "(2, 5) 0.14875\n",
      "(3, 0) 0.24212500000000006\n",
      "(3, 1) 0.131625\n",
      "(3, 2) 0.16287499999999994\n",
      "(3, 3) 0.14662499999999998\n",
      "(3, 4) 0.167\n",
      "(3, 5) 0.14974999999999997\n",
      "(4, 0) 0.24289999999999998\n",
      "(4, 1) 0.131675\n",
      "(4, 2) 0.1634\n",
      "(4, 3) 0.1457375\n",
      "(4, 4) 0.166825\n",
      "(4, 5) 0.1494625\n"
     ]
    }
   ],
   "source": [
    "A, B = baum_welch(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baum Welch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_test(V, a, b, pi, n_iter=100):\n",
    "    M = 6\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(tpm, epm, pi, emissions)\n",
    "        beta = backward(tpm, epm, pi, emissions)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            \n",
    "            denominator = 0\n",
    "            \n",
    "            for state in range(M):\n",
    "                # get emissions index\n",
    "                if V[t + 1] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t + 1] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                const_a = np.dot(alpha[t][state], a)\n",
    "                const_b = b[state][idx]\n",
    "                const_c = beta[t + 1][state]\n",
    "                \n",
    "                # cant np.dot() three items, so doing it in 2 steps\n",
    "                temp = np.dot(const_a, const_b)\n",
    "                denominator += np.dot(temp, const_c)\n",
    "                \n",
    "                \n",
    "            print(denominator)\n",
    "            for i in range(M):\n",
    "                \n",
    "                numerator = 0\n",
    "                for state in range(M):\n",
    "                    # get emissions index\n",
    "                    if V[t + 1] == \"Increasing\":\n",
    "                        idx = 0\n",
    "                    if V[t + 1] == \"Decreasing\":\n",
    "                        idx = 1\n",
    "                        \n",
    "                    numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n",
    "                    \n",
    "                    xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
    "        print(xi)\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        #print(gamma)\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        # number of observations\n",
    "        K = 2\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for emission in range(K):\n",
    "            \n",
    "            for time in range(T - 1):\n",
    "                # get emissions index\n",
    "                if V[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                b_sum = 0\n",
    "                for state_i in range(M):\n",
    "                    if emission == idx:\n",
    "                        b_sum += gamma[state_i][time]\n",
    "                \n",
    "                b[state_i][emission] = b_sum\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[[0.25       0.2625     0.24       0.242125  ]\n",
      "  [0.75       0.7875     0.72       0.726375  ]\n",
      "  [0.5        0.525      0.48       0.48425   ]\n",
      "  [1.75       1.8375     1.68       1.694875  ]\n",
      "  [1.125      1.18125    1.08       1.0895625 ]\n",
      "  [2.5        2.625      2.4        2.42125   ]]\n",
      "\n",
      " [[0.125      0.125      0.13125    0.131625  ]\n",
      "  [0.5        0.5        0.525      0.5265    ]\n",
      "  [0.625      0.625      0.65625    0.658125  ]\n",
      "  [0.4375     0.4375     0.459375   0.4606875 ]\n",
      "  [0.41666667 0.41666667 0.4375     0.43875   ]\n",
      "  [       inf        inf        inf        inf]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.162875  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.375      0.4875     0.5025     0.488625  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.5        0.65       0.67       0.6515    ]\n",
      "  [0.625      0.8125     0.8375     0.814375  ]]\n",
      "\n",
      " [[0.25       0.1375     0.145      0.146625  ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]\n",
      "  [1.5        0.825      0.87       0.87975   ]\n",
      "  [1.75       0.9625     1.015      1.026375  ]\n",
      "  [2.         1.1        1.16       1.173     ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.167     ]\n",
      "  [0.3125     0.40625    0.41875    0.4175    ]\n",
      "  [0.75       0.975      1.005      1.002     ]\n",
      "  [0.875      1.1375     1.1725     1.169     ]\n",
      "  [1.         1.3        1.34       1.336     ]\n",
      "  [0.625      0.8125     0.8375     0.835     ]]\n",
      "\n",
      " [[0.125      0.15       0.14875    0.14975   ]\n",
      "  [0.25       0.3        0.2975     0.2995    ]\n",
      "  [0.375      0.45       0.44625    0.44925   ]\n",
      "  [0.875      1.05       1.04125    1.04825   ]\n",
      "  [1.         1.2        1.19       1.198     ]\n",
      "  [0.625      0.75       0.74375    0.74875   ]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-b8f2ca764a78>:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
      "<ipython-input-28-b8f2ca764a78>:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
      "<ipython-input-28-b8f2ca764a78>:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  b = np.divide(b, denominator.reshape((-1, 1)))\n",
      "<ipython-input-10-4eace1f230cc>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prev_paths_sum += a * b * c\n",
      "<ipython-input-16-96b97f5d25e5>:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  next_paths_sum += a * b *c\n",
      "<ipython-input-28-b8f2ca764a78>:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': array([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]]),\n",
       " 'b': array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch_test(emissions, tpm, epm, pi, n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VITERBI ALGORITHM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, provide us with the sequence of states the HMM most likely has been in to generate such values sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(tpm, epm, pi, observations):\n",
    "    \"\"\"Given a sequence of observed values, provide us with the sequence of states \n",
    "        the HMM most likely has been in to generate such values sequence\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns: array of the most probable state-sequence based on the observations and HMM model\n",
    "    \"\"\"\n",
    "    \n",
    "    num_states = 6\n",
    "    states_names = ['very_low','low','moderate_low','moderate_high','high','very_high' ]\n",
    "    \n",
    "    # create path probability matrix num observations by num states\n",
    "    # initialize to 0\n",
    "    path_probability_matrix = numpy.zeros((len(observations), num_states ))\n",
    "\n",
    "    #create a path backpointer matrix backpointer[N, L + 2] to save indexes of states\n",
    "    # initialize to 0\n",
    "    path_backpointer_maxtrix = numpy.zeros((len(observations)+1, num_states ))\n",
    "    \n",
    "    max_states = np.zeros(len(observations))\n",
    "    final_path=[]\n",
    "    final_path = ['starting' for i in range(len(observations))]\n",
    "\n",
    "    \n",
    "    #grab first observation to determine which EPM index to use\n",
    "    if observations[0] == \"Increasing\":\n",
    "        obs_index = 0\n",
    "    else:\n",
    "        obs_index = 1\n",
    "        \n",
    "    # update first row of path_probability_matrix matrix\n",
    "    # first row = probability of starting in each state * prob of seeing observation in that state\n",
    "    for s in range(num_states):\n",
    "        path_probability_matrix[0][s] = pi[s] * epm[s][obs_index] \n",
    "        \n",
    "    \n",
    "    for t in range(1, len(observations)):\n",
    "        for s in range(num_states):\n",
    "            \n",
    "            backpointer_probabilities = []\n",
    "            probabilities = []\n",
    "            \n",
    "            for s_prime in range(num_states):\n",
    "                \n",
    "                # prob of getting to each previous state through all possible paths\n",
    "                a = path_probability_matrix[t-1][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][s]\n",
    "                \n",
    "                backpointer_prob = a * b\n",
    "                backpointer_probabilities.append(backpointer_prob)\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if observations[t-1] == \"Increasing\":\n",
    "                    c = epm[s][0]\n",
    "                if observations[t-1] == \"Decreasing\":\n",
    "                    c = epm[s][1]\n",
    "                    \n",
    "                path_probability = a * b * c\n",
    "                probabilities.append(path_probability)\n",
    "        \n",
    "            # update path_probability_matrix[t,s] to MAX probability of most prob state for previous observation\n",
    "            path_probability_matrix[t][s] = max(probabilities)\n",
    "\n",
    "            # update back_pointer[t, s] to be argMax calculated of previous obs for given observation\n",
    "            path_backpointer_maxtrix[t][s] = numpy.argmax(backpointer_probabilities)\n",
    "            \n",
    "    #grab end state probability and index \n",
    "    end_state_probability = max(path_probability_matrix[-1:])\n",
    "    end_state_index = numpy.argmax(path_probability_matrix[-1:])\n",
    "\n",
    "    #go backwards through backpointer\n",
    "    final_path[len(observations)-1] = end_state_index\n",
    "    \n",
    "    for i in range(len(observations)-2, -1, -1):\n",
    "        final_path_state = path_backpointer_maxtrix[i+1][int(end_state_index)]\n",
    "        final_path[i] = final_path_state\n",
    "        end_state_index = int(final_path_state)\n",
    "\n",
    "    print(final_path)\n",
    "    return(final_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1    Decreasing\n",
      "2    Increasing\n",
      "3    Decreasing\n",
      "4    Increasing\n",
      "5    Increasing\n",
      "Name: Emission, dtype: object\n",
      "[3.0, 0.0, 2.0, 3.0, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-ca6c5247599a>:64: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  path_probability = a * b * c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0, 0.0, 2.0, 3.0, 5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test using the emissions \n",
    "\n",
    "#emissions_test =  [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "#emissions_test = ['NaN', 'Decreasing', 'Increasing', 'Decreasing', 'Increasing', 'Increasing']\n",
    "emissions_test = df_emission['Emission']\n",
    "print(emissions_test)\n",
    "viterbi(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN\n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing\n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing\n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing\n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing\n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Viterbi Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loop finalpath is ['starting', 'starting', 'starting', 'starting', 5]\n",
      "i is... 3\n",
      "finalpath in for loop is ['starting', 'starting', 'starting', 3.0, 5]\n",
      "i is... 2\n",
      "finalpath in for loop is ['starting', 'starting', 2.0, 3.0, 5]\n",
      "i is... 1\n",
      "finalpath in for loop is ['starting', 0.0, 2.0, 3.0, 5]\n",
      "i is... 0\n",
      "finalpath in for loop is [3.0, 0.0, 2.0, 3.0, 5]\n",
      "[3.0, 0.0, 2.0, 3.0, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-49047bceef66>:64: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  path_probability = a * b * c\n"
     ]
    }
   ],
   "source": [
    "# add the outcome of hidden states to the stock dataframe\n",
    "\n",
    "states_path = viterbi(tpm, epm, pi, emissions)\n",
    "\n",
    "def add_hidden_states_to_df(original_stock_df, states_path):\n",
    "    \"\"\" Add the calcuated hidden state sequence to the original stock dataframe\n",
    "    \n",
    "    Args:\n",
    "        original_stock_df (dataframe): original dataframe with stock information used in HMM\n",
    "        states_path (array): calculated state sequence using HMM\n",
    "    \n",
    "    Returns: updated stock DataFrame including the probable state-sequence based on the observations and HMM model\n",
    "    \"\"\"\n",
    "\n",
    "    states_path_df = pd.DataFrame(states_path,columns=['States_Path'])\n",
    "    states_path_df.loc[-1] = 'starting state' # add starting state because it is NaN row\n",
    "    states_path_df.index = states_path_df.index + 1  # shifting index\n",
    "    states_path_df = states_path_df.sort_index()\n",
    "    states_path_df.T\n",
    "\n",
    "    updated_stock_df = original_stock_df.copy()\n",
    "\n",
    "    updated_stock_df['Hidden_State'] = states_path_df['States_Path']\n",
    "    \n",
    "    return(updated_stock_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "      <th>Hidden_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>starting state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission  \\\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN   \n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing   \n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing   \n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing   \n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing   \n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing   \n",
       "\n",
       "     Hidden_State  \n",
       "0  starting state  \n",
       "1               3  \n",
       "2               0  \n",
       "3               2  \n",
       "4               3  \n",
       "5               5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_stock_df = add_hidden_states_to_df(df_emission, states_path)\n",
    "updated_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_hidden_states(updated_stock_df):\n",
    "    \"\"\" Graph the hidden states by date and close price\n",
    "    \n",
    "    Args:\n",
    "        updated_stock_df (dataframe): dataframe with stock information used in HMM and determined hidden states\n",
    "    \n",
    "    Returns: Nothing, but graphs the input DF.\n",
    "    \"\"\"\n",
    "\n",
    "    dates = updated_stock_df[\"Date\"]\n",
    "    close_v = updated_stock_df[\"Close\"]\n",
    "    states = updated_stock_df[\"Hidden_State\"]\n",
    "\n",
    "    fig, axs = plt.subplots(len(updated_stock_df.Hidden_State.unique()), sharex=True, sharey=True)\n",
    "    colours = cm.rainbow(numpy.linspace(0, 1, (len(updated_stock_df.Hidden_State.unique()))))\n",
    "    for i, (ax, colour) in enumerate(zip(axs, colours)):\n",
    "        # Use fancy indexing to plot data in each state.\n",
    "        mask = states == i\n",
    "        ax.plot_date(dates[mask], close_v[mask], \".-\", c=colour)\n",
    "        ax.set_title(\"{0}th hidden state\".format(i))\n",
    "        ax.xaxis.set_minor_locator(MonthLocator())\n",
    "        ax.grid(True)\n",
    "\n",
    "    # set axis\n",
    "    plt.xlim(dates[0], dates[len(dates)-1])\n",
    "\n",
    "    # set y-axis\n",
    "    plt.ylim(0, numpy.amax(close_v) + 10)\n",
    "\n",
    "    # plt.xlim(1, 10)\n",
    "    fig.set_size_inches(15, 15)\n",
    "    seaborn.set()\n",
    "    plt.show(), states_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_hidden_states(updated_stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
