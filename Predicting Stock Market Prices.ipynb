{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Stock Market Prices Using HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GATHERING AND CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "from datetime import datetime\n",
    "\n",
    "def get_stock_data(file_name):\n",
    "    \"\"\"scrapes and cleans the data from the given file and creates a dataframe\n",
    "    \n",
    "    Args:\n",
    "        file_name (string) : name of file\n",
    "    \n",
    "    Returns:\n",
    "        df_stock (dataframe) : dataframe containing stock info scraped from file\n",
    "    \"\"\"\n",
    "    df_stock = pd.DataFrame()\n",
    "    file = open(file_name)\n",
    "    txt = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    # split text into list, split by new line character\n",
    "    txt = txt.split('\\n')\n",
    "    # get column titles\n",
    "    columns = txt[0].split(',')\n",
    "\n",
    "    for line in txt[1:]:\n",
    "        temp_dict = dict()\n",
    "        line = line.strip()\n",
    "        line_list = line.split(',')\n",
    "\n",
    "        # if row does not have sufficient column information, pass over\n",
    "        if len(columns) != len(line_list):\n",
    "            continue\n",
    "\n",
    "        # add column's corresponding values to a temporary dictionary   \n",
    "        for idx in range(len(columns)):\n",
    "            column_name = columns[idx]\n",
    "            \n",
    "            # change all date column info to datetime object\n",
    "            if column_name == 'Date':\n",
    "                temp_dict[column_name] = datetime.strptime(line_list[idx], '%Y-%m-%d')\n",
    "            else:\n",
    "                temp_dict[column_name] = line_list[idx]\n",
    "\n",
    "        # append dictionary to dataframe                                                  \n",
    "        df_stock = df_stock.append(temp_dict, ignore_index=True)\n",
    "    \n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>OpenInt</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>33.754</td>\n",
       "      <td>27.002</td>\n",
       "      <td>30.713</td>\n",
       "      <td>0</td>\n",
       "      <td>66277506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.257</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>29.027</td>\n",
       "      <td>26.872</td>\n",
       "      <td>28.986</td>\n",
       "      <td>0</td>\n",
       "      <td>16142920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.044</td>\n",
       "      <td>27.886</td>\n",
       "      <td>0</td>\n",
       "      <td>6970266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.002</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>29.446</td>\n",
       "      <td>27.002</td>\n",
       "      <td>28.688</td>\n",
       "      <td>0</td>\n",
       "      <td>6332082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.717</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.309</td>\n",
       "      <td>27.002</td>\n",
       "      <td>27.083</td>\n",
       "      <td>0</td>\n",
       "      <td>5132147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>68.22</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>68.45</td>\n",
       "      <td>68.22</td>\n",
       "      <td>68.22</td>\n",
       "      <td>0</td>\n",
       "      <td>995731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>68.25</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>68.64</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.32</td>\n",
       "      <td>0</td>\n",
       "      <td>966466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>68.11</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>68.33</td>\n",
       "      <td>67.771</td>\n",
       "      <td>68.1</td>\n",
       "      <td>0</td>\n",
       "      <td>972616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>67.47</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>67.98</td>\n",
       "      <td>66.91</td>\n",
       "      <td>67.92</td>\n",
       "      <td>0</td>\n",
       "      <td>1673083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>66.81</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>67.58</td>\n",
       "      <td>66.7</td>\n",
       "      <td>67.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1704549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4521 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Close       Date    High     Low    Open OpenInt    Volume\n",
       "0     29.702 1999-11-18  33.754  27.002  30.713       0  66277506\n",
       "1     27.257 1999-11-19  29.027  26.872  28.986       0  16142920\n",
       "2     29.702 1999-11-22  29.702  27.044  27.886       0   6970266\n",
       "3     27.002 1999-11-23  29.446  27.002  28.688       0   6332082\n",
       "4     27.717 1999-11-24  28.309  27.002  27.083       0   5132147\n",
       "...      ...        ...     ...     ...     ...     ...       ...\n",
       "4516   68.22 2017-11-06   68.45   68.22   68.22       0    995731\n",
       "4517   68.25 2017-11-07   68.64   68.04   68.32       0    966466\n",
       "4518   68.11 2017-11-08   68.33  67.771    68.1       0    972616\n",
       "4519   67.47 2017-11-09   67.98   66.91   67.92       0   1673083\n",
       "4520   66.81 2017-11-10   67.58    66.7   67.35       0   1704549\n",
       "\n",
       "[4521 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'a.us.txt'\n",
    "df_a_stock = get_stock_data(file_name)\n",
    "df_a_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_stock_files = ['a.us.txt', 'abc.us.txt', 'aktx.us.txt', 'blue.us.txt', 'bro.us.txt', 'by.us.txt',\n",
    "                    'casi.us.txt', 'cbu.us.txt', 'cxdc.us.txt', 'dhr.us.txt', 'dxyn.us.txt', 'ebay.us.txt',\n",
    "                    'eei.us.txt', 'eod.us.txt', 'fox.us.txt', 'ftrpr.us.txt', 'fwonk.us.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission(stock_dataframe):\n",
    "    \"\"\" Calculates the one day difference between stock closing value (today - yesterday)\n",
    "        and determines emission symbol based on if stock price increased or decreased from previous day\n",
    "    \n",
    "    Args:\n",
    "        stock_dataframe (dataframe) : dataframe containing stock info(close value, date, high, low, open, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        one_day_dif_df(dataframe) : dataframe containing the difference from the previous day's stock value\n",
    "                                    as well as the related emission symbol (Increasing or Decreasing)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset the initial DF to obtain only relevant columns\n",
    "    one_day_dif_df = stock_dataframe.copy()\n",
    "    one_day_dif_df = one_day_dif_df[['Date','Close']]\n",
    "    \n",
    "    # Convert CV to numeric for calculations\n",
    "    one_day_dif_df['Close'] = pd.to_numeric(one_day_dif_df['Close'])\n",
    "    one_day_dif_df['Yesterday Close'] = one_day_dif_df['Close'].shift()\n",
    "    \n",
    "    # Calculate the stock's closing price difference from the previous day\n",
    "    one_day_dif_df['Close Value Difference'] = round((one_day_dif_df['Close'] - one_day_dif_df['Yesterday Close']),2)\n",
    "    \n",
    "    one_day_dif_df['Emission'] = 'NaN'\n",
    "    row_indexes_inc = one_day_dif_df[one_day_dif_df['Close Value Difference']>=0].index\n",
    "    row_indexes_dec = one_day_dif_df[one_day_dif_df['Close Value Difference']<0].index\n",
    "    \n",
    "    one_day_dif_df.loc[row_indexes_inc,'Emission']='Increasing'\n",
    "    one_day_dif_df.loc[row_indexes_dec,'Emission']='Decreasing'\n",
    "    #one_day_dif_df['Emission'] = ['Increasing' if x > 0 else 'Decreasing' for x in one_day_dif_df['Close Value Difference']]\n",
    "    \n",
    "    return one_day_dif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN\n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing\n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing\n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing\n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emission = get_emission(df_a_stock)\n",
    "df_emission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMP AND TMP MATRIX INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TPM(n):\n",
    "    \"\"\"creates transition probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        \n",
    "    Returns:\n",
    "        tpm (array of arrays) : n by n transition probability matrix\n",
    "                                    s1 s2 s3 s4 s5 s6\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    tpm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / n, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(n):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        tpm.append(row)\n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = create_TPM(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_EPM(n, m):\n",
    "    \"\"\"creates emissions probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        m (int) : number of possible observation symbols\n",
    "        \n",
    "    Returns:\n",
    "        epm (array of arrays) : n by m emission probability matrix\n",
    "                                    I  D\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    \n",
    "    epm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / m, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(m):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        epm.append(row)\n",
    "        \n",
    "    return epm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epm = create_EPM(6, 2)\n",
    "epm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD BACKWARD ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Forward Backward Algorithm: the probability of an observation sequence occurring given the model. \n",
    "\n",
    "- Forward: probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "- Backward: probability that we will see a certain sequence of future observations, given we are in a certain state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Initialization visualization: \n",
    "        S1 S2 S3 S4 S5 S6\n",
    "    T1  .2 .1 .1 .2 .1 .1  (PI)\n",
    "        * EPM - probability of emitting whatever our first observation is \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    alpha = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            if OBSERVATIONS[T] == \"Increasing\":\n",
    "                row.append(pi[N] * epm[N][0])\n",
    "            if OBSERVATIONS[T] == \"Decreasing\":\n",
    "                row.append(pi[N] * epm[N][1])\n",
    "            \n",
    "        alpha.append(row)\n",
    "\n",
    "    # for each time step from 2 to T\n",
    "    for time in range(1, len(OBSERVATIONS)):\n",
    "        curr_time_idx = time\n",
    "        prev_time_idx = curr_time_idx - 1\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            prev_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each previous state through all possible paths \n",
    "                a = alpha[prev_time_idx][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][state]\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[state][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[state][1]\n",
    "                    \n",
    "                prev_paths_sum += a * b * c\n",
    "\n",
    "            alpha[curr_time_idx][state] = prev_paths_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = [[0.2, 0.1, 0.3, 0.1, 0.2, 0.1],\n",
    "       [0.3, 0.1, 0.1, 0.2, 0.3, 0],\n",
    "       [0.1, 0.1, 0.1, 0.3, 0.2, 0.2],\n",
    "       [0.4, 0.1, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.3, 0.2, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.1, 0.1, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.05, 0.05, 0.1, 0.05, 0.05]\n",
      "[0.052500000000000005, 0.025000000000000005, 0.0325, 0.027500000000000004, 0.03250000000000001, 0.030000000000000006]\n",
      "[0.024, 0.013125000000000003, 0.01675, 0.014500000000000006, 0.016750000000000004, 0.014875000000000003]\n",
      "[0.012106250000000004, 0.006581250000000001, 0.00814375, 0.007331250000000001, 0.008350000000000003, 0.007487500000000001]\n",
      "[0.0060725000000000015, 0.003291875000000001, 0.004085000000000001, 0.003643437500000001, 0.004170625000000002, 0.003736562500000001]\n"
     ]
    }
   ],
   "source": [
    "emissions = [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "pi = [.2, .1, .1, .2, .1, .1]\n",
    "frd = forward(tpm, epm, pi, emissions)\n",
    "for observation in frd:\n",
    "    print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_test(V, a, b, pi):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        V : emission matrix\n",
    "        a : tpm\n",
    "        b : epm\n",
    "        pi : initial distribution\n",
    "    \n",
    "    Returns:\n",
    "        alpha\n",
    "        \n",
    "    Citation:\n",
    "        https://datascience.stackexchange.com/questions/74126/hidden-markov-model-forward-algorithm-implementation-in-python\n",
    "    \"\"\"\n",
    "    alpha = np.zeros((len(V), len(a)))\n",
    "    \n",
    "    # alpha[0, :] = pi * b[:, V[0]]\n",
    "    for state in range(len(alpha[0])):\n",
    "        if V[0] == \"Increasing\":\n",
    "                ob = epm[state][0]\n",
    "        if V[0] == \"Decreasing\":\n",
    "                ob = epm[state][1]\n",
    "                \n",
    "        alpha[0][state] = pi[state] * ob  \n",
    "    \n",
    "    # for each observation, 1 to T\n",
    "    for t in range(1, len(V)):\n",
    "        # for each state\n",
    "        for j in range(len(a)):\n",
    "            \n",
    "            prev_state_sum = 0\n",
    "            # for each state\n",
    "            for s_prime in range(len(a)):\n",
    "                \n",
    "                if V[t] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                prev_state_sum += alpha[t - 1][s_prime] * a[s_prime][j] * b[j][idx]\n",
    "            \n",
    "            alpha[t][j] = prev_state_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.05 0.05 0.1  0.05 0.05]\n",
      "[0.0525 0.025  0.0325 0.0275 0.0325 0.03  ]\n",
      "[0.024    0.013125 0.01675  0.0145   0.01675  0.014875]\n",
      "[0.01210625 0.00658125 0.00814375 0.00733125 0.00835    0.0074875 ]\n",
      "[0.0060725  0.00329188 0.004085   0.00364344 0.00417063 0.00373656]\n"
     ]
    }
   ],
   "source": [
    "frd_test = forward_test(emissions, tpm, epm, pi)\n",
    "\n",
    "for state in frd_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(frd)):\n",
    "    for state in range(len(frd[observation])):\n",
    "        # print(frd_test[observation][state], frd[observation][state])\n",
    "        assert frd_test[observation][state] == frd[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we will see a certain sequence of future observations, given we are in a certain state\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        backwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    beta = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            row.append(1.0)\n",
    "        \n",
    "        beta.append(row)\n",
    "    \n",
    "    # recursion\n",
    "    # for each time step from T-1 to 1 (end is exclusive)\n",
    "    for time in range(len(OBSERVATIONS) - 2, -1, -1):\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            next_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each next state through all possible paths \n",
    "                a = beta[time+1][s_prime]\n",
    "                \n",
    "                # the transition probability from next S to current S\n",
    "                b = tpm[state][s_prime]\n",
    "                \n",
    "                # the emission probability of emitting observation at next S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[s_prime][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[s_prime][1]\n",
    "                    \n",
    "                next_paths_sum += a * b *c\n",
    "\n",
    "            beta[time][state] = next_paths_sum\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06250000000000001, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125]\n",
      "[0.25000000000000006, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "[0.5000000000000001, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "back = backward(tpm, epm, pi, emissions)\n",
    "for state in back:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_test(observations, trans, emis, numstates):\n",
    "    backwardmatrix = numpy.zeros((len(observations), numstates))\n",
    "\n",
    "    # initialization\n",
    "    for s in range(numstates):\n",
    "        backwardmatrix[len(observations) - 1][s] = 1.0\n",
    "\n",
    "    # recursion\n",
    "    for t in range(len(observations) - 2, -1, -1):\n",
    "        \n",
    "        if observations[t] == \"Increasing\":\n",
    "            obs_index = 0\n",
    "        if observations[t] == \"Decreasing\":\n",
    "            obs_index = 1\n",
    "        \n",
    "        for s in range(numstates):\n",
    "            \n",
    "            for s2 in range(numstates):\n",
    "                backwardmatrix[t][s] += trans[s][s2] * emis[s2][obs_index] * backwardmatrix[t+1][s2]\n",
    "\n",
    "    return backwardmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "[0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "back_test = backward_test(emissions, tpm, epm, 6)\n",
    "\n",
    "for state in back_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(emissions)):\n",
    "    for state in range(len(back[observation])):\n",
    "        # print(back_test[observation][state], back[observation][state])\n",
    "        assert back_test[observation][state] == back[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frwd_backwd(tpm, epm, init, observations):\n",
    "    \"\"\"the probability of an observation sequence occurring given the model\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        init () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd_backwd (int) : probability of an observation sequence occurring\n",
    "    \"\"\"\n",
    "    frwd = forward(tpm, epm, pi, observations)\n",
    "    bkwd = backward(tpm, epm, pi, observations)\n",
    "\n",
    "    # matrix multiplication\n",
    "    result = [[sum(frwd*bkwd for frwd,bkwd in zip(X_row,Y_col)) for Y_col in zip(*bkwd)] for X_row in frwd]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
       " [0.060781250000000016,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001],\n",
       " [0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001],\n",
       " [0.015630859375000007,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004],\n",
       " [0.007804609375000004,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frwd_backwd(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAUM WELCH ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, determine the parameters of the HMM that generated that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frwd = forward(tpm, epm, pi, emissions)\n",
    "bkwd = backward(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convergence(old_matrix, new_matrix):\n",
    "    \"\"\"returns true if matricies have converged (aka are the same), false otherwise\n",
    "    \n",
    "    Args:\n",
    "        old_matrix (array of arrays) : old matrix\n",
    "        new_matrix (array of arrays) : new matrix\n",
    "        \n",
    "    Returns:\n",
    "        converge (boolean) : represents whether the given matricies have converged or not\n",
    "        \n",
    "    \"\"\"\n",
    "    converge = True\n",
    "    for col in range(len(old_matrix)):\n",
    "        for row in range(len(old_matrix[col])):\n",
    "            if old_matrix[col][row] != new_matrix[col][row]:\n",
    "                converge = False\n",
    "    \n",
    "    return converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test check_covergence()\n",
    "\n",
    "old_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "new_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new_matrix) == True, \"method claims matricies have not converged\"\n",
    "\n",
    "new2_matrix = [[1, 2], [2, 2], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new2_matrix) == False, \"method claims matricies have converged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(tpm, epm, pi, emissions):\n",
    "    \"\"\"probability of initial parameters that generated emissions data\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # transition probabilities\n",
    "    A = np.zeros((6, 6))\n",
    "    # observation probabilities\n",
    "    B = np.ones((len(emissions) + 1, 2))\n",
    "    \n",
    "    # xi dictionary\n",
    "    xi = dict()\n",
    "    # gamma dictionary\n",
    "    gamma = dict()\n",
    "    \n",
    "    # iterate until convergence\n",
    "    # while (check_convergence(tpm, A) == False and check_convergence(epm, B) == False):\n",
    "    \n",
    "    # HOW CHECK CONVERGENCE? JUST RUN 10 TIMES\n",
    "    for i in range(10):\n",
    "        \n",
    "        # E STEP\n",
    "\n",
    "        for time in range(len(emissions)):\n",
    "    \n",
    "             # get normalization constant for time P(O|HMM)\n",
    "            normalization_const = 0\n",
    "            for state in range(6):\n",
    "                normalization_const += frwd[time][state] * bkwd[time][state]\n",
    "\n",
    "            for state_i in range(6):\n",
    "                # update gamma values for (time, state_i) in gamma dictionary\n",
    "                gamma[(time, state_i)] = (frwd[time][state_i] * bkwd[time][state_i]) / normalization_const\n",
    "\n",
    "        for time in range(len(emissions) - 1):\n",
    "\n",
    "                # get emissions index\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if emissions[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "\n",
    "                for state_i in range(6):\n",
    "\n",
    "                    for state_j in range(6):\n",
    "\n",
    "                        # update xi values for (time, state_i, state_j) in xi dictionary\n",
    "                        temp_xi = frwd[time][state_j] * tpm[state_i][state_j] * epm[state_j][idx] * bkwd[time + 1][state_j]\n",
    "                        xi[(time, state_i, state_j)] = temp_xi / normalization_const\n",
    "        \n",
    "        # M STEP\n",
    "        \n",
    "        # update alpha\n",
    "        for state_i in range(6):\n",
    "            for state_j in range(6):\n",
    "\n",
    "                nominator_sum = 0\n",
    "                denom_sum = 0\n",
    "\n",
    "                for time in range(1, len(emissions) - 1):\n",
    "                    nominator_sum += xi[(time, state_i, state_j)]\n",
    "\n",
    "                    temp_sum = 0\n",
    "                    for state_prime in range(6):\n",
    "                        temp_sum += xi[(time, state_i, state_prime)]\n",
    "\n",
    "                    denom_sum += temp_sum\n",
    "\n",
    "                A[state_i][state_j] = nominator_sum / denom_sum\n",
    "\n",
    "        # update beta\n",
    "\n",
    "        increasing_idx = 0     # tracked observation variable\n",
    "        for state in range(6):\n",
    "\n",
    "            numerator = 0\n",
    "            denom = 0\n",
    "\n",
    "            for time in range(len(emissions)):\n",
    "\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    numerator += gamma[(time, state)]\n",
    "\n",
    "                denom += gamma[(time, state)]\n",
    "\n",
    "                B[state][increasing_idx] = numerator / denom\n",
    "                B[state][1] = 1 - (numerator / denom)\n",
    "    for item in gamma:\n",
    "        print(item, gamma[item])\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0.25000000000000006\n",
      "(0, 1) 0.125\n",
      "(0, 2) 0.125\n",
      "(0, 3) 0.25\n",
      "(0, 4) 0.125\n",
      "(0, 5) 0.125\n",
      "(1, 0) 0.26250000000000007\n",
      "(1, 1) 0.125\n",
      "(1, 2) 0.16249999999999998\n",
      "(1, 3) 0.13749999999999998\n",
      "(1, 4) 0.1625\n",
      "(1, 5) 0.15\n",
      "(2, 0) 0.24000000000000002\n",
      "(2, 1) 0.13125\n",
      "(2, 2) 0.16749999999999998\n",
      "(2, 3) 0.14500000000000002\n",
      "(2, 4) 0.1675\n",
      "(2, 5) 0.14875\n",
      "(3, 0) 0.24212500000000006\n",
      "(3, 1) 0.131625\n",
      "(3, 2) 0.16287499999999994\n",
      "(3, 3) 0.14662499999999998\n",
      "(3, 4) 0.167\n",
      "(3, 5) 0.14974999999999997\n",
      "(4, 0) 0.24289999999999998\n",
      "(4, 1) 0.131675\n",
      "(4, 2) 0.1634\n",
      "(4, 3) 0.1457375\n",
      "(4, 4) 0.166825\n",
      "(4, 5) 0.1494625\n"
     ]
    }
   ],
   "source": [
    "A, B = baum_welch(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baum Welch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_test(V, a, b, pi, n_iter=100):\n",
    "    M = 6\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(tpm, epm, pi, emissions)\n",
    "        beta = backward(tpm, epm, pi, emissions)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            \n",
    "            denominator = 0\n",
    "            \n",
    "            for state in range(M):\n",
    "                # get emissions index\n",
    "                if V[t + 1] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t + 1] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                const_a = np.dot(alpha[t][state], a)\n",
    "                const_b = b[state][idx]\n",
    "                const_c = beta[t + 1][state]\n",
    "                \n",
    "                # cant np.dot() three items, so doing it in 2 steps\n",
    "                temp = np.dot(const_a, const_b)\n",
    "                denominator += np.dot(temp, const_c)\n",
    "                \n",
    "                \n",
    "            print(denominator)\n",
    "            for i in range(M):\n",
    "                \n",
    "                numerator = 0\n",
    "                for state in range(M):\n",
    "                    # get emissions index\n",
    "                    if V[t + 1] == \"Increasing\":\n",
    "                        idx = 0\n",
    "                    if V[t + 1] == \"Decreasing\":\n",
    "                        idx = 1\n",
    "                        \n",
    "                    numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n",
    "                    \n",
    "                    xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
    "        print(xi)\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        #print(gamma)\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        # number of observations\n",
    "        K = 2\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for emission in range(K):\n",
    "            \n",
    "            for time in range(T - 1):\n",
    "                # get emissions index\n",
    "                if V[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                b_sum = 0\n",
    "                for state_i in range(M):\n",
    "                    if emission == idx:\n",
    "                        b_sum += gamma[state_i][time]\n",
    "                \n",
    "                b[state_i][emission] = b_sum\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[[0.25       0.2625     0.24       0.242125  ]\n",
      "  [0.75       0.7875     0.72       0.726375  ]\n",
      "  [0.5        0.525      0.48       0.48425   ]\n",
      "  [1.75       1.8375     1.68       1.694875  ]\n",
      "  [1.125      1.18125    1.08       1.0895625 ]\n",
      "  [2.5        2.625      2.4        2.42125   ]]\n",
      "\n",
      " [[0.125      0.125      0.13125    0.131625  ]\n",
      "  [0.5        0.5        0.525      0.5265    ]\n",
      "  [0.625      0.625      0.65625    0.658125  ]\n",
      "  [0.4375     0.4375     0.459375   0.4606875 ]\n",
      "  [0.41666667 0.41666667 0.4375     0.43875   ]\n",
      "  [       inf        inf        inf        inf]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.162875  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.375      0.4875     0.5025     0.488625  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.5        0.65       0.67       0.6515    ]\n",
      "  [0.625      0.8125     0.8375     0.814375  ]]\n",
      "\n",
      " [[0.25       0.1375     0.145      0.146625  ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]\n",
      "  [1.5        0.825      0.87       0.87975   ]\n",
      "  [1.75       0.9625     1.015      1.026375  ]\n",
      "  [2.         1.1        1.16       1.173     ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.167     ]\n",
      "  [0.3125     0.40625    0.41875    0.4175    ]\n",
      "  [0.75       0.975      1.005      1.002     ]\n",
      "  [0.875      1.1375     1.1725     1.169     ]\n",
      "  [1.         1.3        1.34       1.336     ]\n",
      "  [0.625      0.8125     0.8375     0.835     ]]\n",
      "\n",
      " [[0.125      0.15       0.14875    0.14975   ]\n",
      "  [0.25       0.3        0.2975     0.2995    ]\n",
      "  [0.375      0.45       0.44625    0.44925   ]\n",
      "  [0.875      1.05       1.04125    1.04825   ]\n",
      "  [1.         1.2        1.19       1.198     ]\n",
      "  [0.625      0.75       0.74375    0.74875   ]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-b8f2ca764a78>:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
      "<ipython-input-28-b8f2ca764a78>:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
      "<ipython-input-28-b8f2ca764a78>:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  b = np.divide(b, denominator.reshape((-1, 1)))\n",
      "<ipython-input-10-4eace1f230cc>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prev_paths_sum += a * b * c\n",
      "<ipython-input-16-96b97f5d25e5>:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  next_paths_sum += a * b *c\n",
      "<ipython-input-28-b8f2ca764a78>:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': array([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]]),\n",
       " 'b': array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch_test(emissions, tpm, epm, pi, n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VITERBI ALGORITHM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, provide us with the sequence of states the HMM most likely has been in to generate such values sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(tpm, epm, pi, observations):\n",
    "    \n",
    "    num_states = 6\n",
    "    states_names = ['very_low','low','moderate_low','moderate_high','high','very_high' ]\n",
    "    \n",
    "    # create path probability matrix num observations by num states\n",
    "    # initialize to 0\n",
    "    path_probability_matrix = numpy.zeros((len(observations), num_states ))\n",
    "\n",
    "    #create a path backpointer matrix backpointer[N, L + 2] to save indexes of states\n",
    "    # initialize to 0\n",
    "    path_backpointer_maxtrix = numpy.zeros((len(observations), num_states ))\n",
    "    \n",
    "    max_states = np.zeros(len(observations))\n",
    "    final_path=[]\n",
    "    final_path = ['starting' for i in range(len(observations))]\n",
    "    print('finalpath is', final_path)\n",
    "    \n",
    "    #grab first observation to determine which EPM index to use\n",
    "    if observations[0] == \"Increasing\":\n",
    "        obs_index = 0\n",
    "    else:\n",
    "        obs_index = 1\n",
    "        \n",
    "    # update first row of path_probability_matrix matrix\n",
    "    # first row = probability of starting in each state * prob of seeing observation in that state\n",
    "    for s in range(num_states):\n",
    "        path_probability_matrix[0][s] = pi[s] * epm[s][obs_index]  \n",
    "    \n",
    "    for t in range(1, len(observations)):\n",
    "        for s in range(num_states):\n",
    "            \n",
    "            backpointer_probabilities = []\n",
    "            probabilities = []\n",
    "            \n",
    "            for s_prime in range(num_states):\n",
    "                \n",
    "                # prob of getting to each previous state through all possible paths\n",
    "                a = path_probability_matrix[t-1][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][s]\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if observations[t-1] == \"Increasing\":\n",
    "                    c = epm[s][0]\n",
    "                if observations[t-1] == \"Decreasing\":\n",
    "                    c = epm[s][1]\n",
    "                    \n",
    "                path_probability = a * b * c\n",
    "                probabilities.append(path_probability)\n",
    "        \n",
    "            # update path_probability_matrix[t,s] to MAX probability of most prob state for previous observation\n",
    "            path_probability_matrix[t][s] = max(probabilities)\n",
    "\n",
    "            # update back_pointer[t, s] to be argMax calculated of previous obs for given observation\n",
    "            path_backpointer_maxtrix[t][s] = numpy.argmax(probabilities)\n",
    "            \n",
    "    #grab end state probability and index \n",
    "    end_state_probability = max(path_probability_matrix[-1:])\n",
    "    end_state_index = numpy.argmax(path_probability_matrix[-1:])\n",
    "    \n",
    "    #backtrack through the backpointer matrix, starting with the most probable last state calculated\n",
    "    print('end_state_index is..', end_state_index, 'and finalpath is',final_path)\n",
    "    \n",
    "    #go backwards through backpointer\n",
    "    print('path_probability_matrix \\n', path_probability_matrix)\n",
    "\n",
    "    print(\"\\n before loop path_backpointer_maxtrix\", path_backpointer_maxtrix)\n",
    "    final_path[len(observations)-1] = end_state_index\n",
    "\n",
    "    for i in range(len(observations)-1, -1, -1):\n",
    "        final_path_state = path_backpointer_maxtrix[i][end_state_index]\n",
    "        final_path[i] = final_path_state\n",
    "        end_state_index = int(final_path_state)\n",
    "\n",
    "    print(final_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalpath is ['starting', 'starting', 'starting', 'starting', 'starting']\n",
      "end_state_index is.. 5 and finalpath is ['starting', 'starting', 'starting', 'starting', 'starting']\n",
      "path_probability_matrix \n",
      " [[1.00e-01 5.00e-02 5.00e-02 1.00e-01 5.00e-02 0.00e+00]\n",
      " [2.00e-02 5.00e-03 1.50e-02 7.50e-03 1.00e-02 0.00e+00]\n",
      " [2.00e-03 1.00e-03 3.00e-03 2.25e-03 2.00e-03 0.00e+00]\n",
      " [4.50e-04 2.00e-04 3.00e-04 4.50e-04 3.00e-04 0.00e+00]\n",
      " [9.00e-05 3.00e-05 6.75e-05 4.50e-05 4.50e-05      inf]]\n",
      "\n",
      " before loop path_backpointer_maxtrix [[0. 0. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0.]\n",
      " [3. 4. 0. 2. 2. 0.]\n",
      " [3. 4. 0. 2. 0. 1.]]\n",
      "[0.0, 3.0, 0.0, 4.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-c22c37c4bc98>:50: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  path_probability = a * b * c\n"
     ]
    }
   ],
   "source": [
    "# test using the emissions \n",
    "emissions_test =  [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "\n",
    "viterbi(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
