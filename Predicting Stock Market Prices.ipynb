{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Stock Market Prices Using HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GATHERING AND CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm, pyplot as plt\n",
    "import seaborn\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator\n",
    "import pandas as pd\n",
    "import numpy \n",
    "from datetime import datetime\n",
    "\n",
    "def get_stock_data(file_name):\n",
    "    \"\"\"scrapes and cleans the data from the given file and creates a dataframe\n",
    "    \n",
    "    Args:\n",
    "        file_name (string) : name of file\n",
    "    \n",
    "    Returns:\n",
    "        df_stock (dataframe) : dataframe containing stock info scraped from file\n",
    "    \"\"\"\n",
    "    df_stock = pd.DataFrame()\n",
    "    file = open(file_name)\n",
    "    txt = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    # split text into list, split by new line character\n",
    "    txt = txt.split('\\n')\n",
    "    # get column titles\n",
    "    columns = txt[0].split(',')\n",
    "\n",
    "    for line in txt[1:]:\n",
    "        temp_dict = dict()\n",
    "        line = line.strip()\n",
    "        line_list = line.split(',')\n",
    "\n",
    "        # if row does not have sufficient column information, pass over\n",
    "        if len(columns) != len(line_list):\n",
    "            continue\n",
    "\n",
    "        # add column's corresponding values to a temporary dictionary   \n",
    "        for idx in range(len(columns)):\n",
    "            column_name = columns[idx]\n",
    "            \n",
    "            # change all date column info to datetime object\n",
    "            if column_name == 'Date':\n",
    "                temp_dict[column_name] = datetime.strptime(line_list[idx], '%Y-%m-%d')\n",
    "            else:\n",
    "                temp_dict[column_name] = line_list[idx]\n",
    "\n",
    "        # append dictionary to dataframe                                                  \n",
    "        df_stock = df_stock.append(temp_dict, ignore_index=True)\n",
    "    \n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>OpenInt</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>33.754</td>\n",
       "      <td>27.002</td>\n",
       "      <td>30.713</td>\n",
       "      <td>0</td>\n",
       "      <td>66277506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.257</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>29.027</td>\n",
       "      <td>26.872</td>\n",
       "      <td>28.986</td>\n",
       "      <td>0</td>\n",
       "      <td>16142920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.702</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.044</td>\n",
       "      <td>27.886</td>\n",
       "      <td>0</td>\n",
       "      <td>6970266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.002</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>29.446</td>\n",
       "      <td>27.002</td>\n",
       "      <td>28.688</td>\n",
       "      <td>0</td>\n",
       "      <td>6332082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.717</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.309</td>\n",
       "      <td>27.002</td>\n",
       "      <td>27.083</td>\n",
       "      <td>0</td>\n",
       "      <td>5132147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.807</td>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>28.012</td>\n",
       "      <td>27.509</td>\n",
       "      <td>27.594</td>\n",
       "      <td>0</td>\n",
       "      <td>1832635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Close       Date    High     Low    Open OpenInt    Volume\n",
       "0  29.702 1999-11-18  33.754  27.002  30.713       0  66277506\n",
       "1  27.257 1999-11-19  29.027  26.872  28.986       0  16142920\n",
       "2  29.702 1999-11-22  29.702  27.044  27.886       0   6970266\n",
       "3  27.002 1999-11-23  29.446  27.002  28.688       0   6332082\n",
       "4  27.717 1999-11-24  28.309  27.002  27.083       0   5132147\n",
       "5  27.807 1999-11-26  28.012  27.509  27.594       0   1832635"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'a.us.txt'\n",
    "df_a_stock = get_stock_data(file_name)\n",
    "\n",
    "test_df = df_a_stock.head(6)\n",
    "test_df\n",
    "#df_a_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_stock_files = ['a.us.txt', 'abc.us.txt', 'aktx.us.txt', 'blue.us.txt', 'bro.us.txt', 'by.us.txt',\n",
    "                    'casi.us.txt', 'cbu.us.txt', 'cxdc.us.txt', 'dhr.us.txt', 'dxyn.us.txt', 'ebay.us.txt',\n",
    "                    'eei.us.txt', 'eod.us.txt', 'fox.us.txt', 'ftrpr.us.txt', 'fwonk.us.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission(stock_dataframe):\n",
    "    \"\"\" Calculates the one day difference between stock closing value (today - yesterday)\n",
    "        and determines emission symbol based on if stock price increased or decreased from previous day\n",
    "    \n",
    "    Args:\n",
    "        stock_dataframe (dataframe) : dataframe containing stock info(close value, date, high, low, open, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        one_day_dif_df(dataframe) : dataframe containing the difference from the previous day's stock value\n",
    "                                    as well as the related emission symbol (Increasing or Decreasing)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset the initial DF to obtain only relevant columns\n",
    "    one_day_dif_df = stock_dataframe.copy()\n",
    "    one_day_dif_df = one_day_dif_df[['Date','Close']]\n",
    "    \n",
    "    # Convert CV to numeric for calculations\n",
    "    one_day_dif_df['Close'] = pd.to_numeric(one_day_dif_df['Close'])\n",
    "    one_day_dif_df['Yesterday Close'] = one_day_dif_df['Close'].shift()\n",
    "    \n",
    "    # Calculate the stock's closing price difference from the previous day\n",
    "    one_day_dif_df['Close Value Difference'] = round((one_day_dif_df['Close'] - one_day_dif_df['Yesterday Close']),2)\n",
    "    \n",
    "    one_day_dif_df['Emission'] = 'NaN'\n",
    "    row_indexes_inc = one_day_dif_df[one_day_dif_df['Close Value Difference']>=0].index\n",
    "    row_indexes_dec = one_day_dif_df[one_day_dif_df['Close Value Difference']<0].index\n",
    "    \n",
    "    one_day_dif_df.loc[row_indexes_inc,'Emission']='Increasing'\n",
    "    one_day_dif_df.loc[row_indexes_dec,'Emission']='Decreasing'\n",
    "    #one_day_dif_df['Emission'] = ['Increasing' if x > 0 else 'Decreasing' for x in one_day_dif_df['Close Value Difference']]\n",
    "    \n",
    "    return one_day_dif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN\n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing\n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing\n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing\n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing\n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emission = get_emission(test_df)\n",
    "df_emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMP AND TMP MATRIX INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TPM(n):\n",
    "    \"\"\"creates transition probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        \n",
    "    Returns:\n",
    "        tpm (array of arrays) : n by n transition probability matrix\n",
    "                                    s1 s2 s3 s4 s5 s6\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    tpm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / n, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(n):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        tpm.append(row)\n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = create_TPM(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_EPM(n, m):\n",
    "    \"\"\"creates emissions probability matrix and initializes to equal random probabilities\n",
    "    \n",
    "    Args:\n",
    "        n (int) : number of possible states\n",
    "        m (int) : number of possible observation symbols\n",
    "        \n",
    "    Returns:\n",
    "        epm (array of arrays) : n by m emission probability matrix\n",
    "                                    I  D\n",
    "                                s1\n",
    "                                s2\n",
    "                                s3\n",
    "                                s4\n",
    "                                s5\n",
    "                                s6\n",
    "    \"\"\"\n",
    "    \n",
    "    epm = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        rand_prob = round(1 / m, 2)\n",
    "        row = []\n",
    "        \n",
    "        for idx in range(m):\n",
    "            row.append(rand_prob)\n",
    "            \n",
    "        epm.append(row)\n",
    "        \n",
    "    return epm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epm = create_EPM(6, 2)\n",
    "epm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD BACKWARD ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Forward Backward Algorithm: the probability of an observation sequence occurring given the model. \n",
    "\n",
    "- Forward: probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "- Backward: probability that we will see a certain sequence of future observations, given we are in a certain state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we are in a certain state, given we observed a certain sequence of historical observations\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Initialization visualization: \n",
    "        S1 S2 S3 S4 S5 S6\n",
    "    T1  .2 .1 .1 .2 .1 .1  (PI)\n",
    "        * EPM - probability of emitting whatever our first observation is \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    alpha = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            if OBSERVATIONS[T] == \"Increasing\":\n",
    "                row.append(pi[N] * epm[N][0])\n",
    "            if OBSERVATIONS[T] == \"Decreasing\":\n",
    "                row.append(pi[N] * epm[N][1])\n",
    "            \n",
    "        alpha.append(row)\n",
    "\n",
    "    # for each time step from 2 to T\n",
    "    for time in range(1, len(OBSERVATIONS)):\n",
    "        curr_time_idx = time\n",
    "        prev_time_idx = curr_time_idx - 1\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            prev_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each previous state through all possible paths \n",
    "                a = alpha[prev_time_idx][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][state]\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[state][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[state][1]\n",
    "                    \n",
    "                prev_paths_sum += a * b * c\n",
    "\n",
    "            alpha[curr_time_idx][state] = prev_paths_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = [[0.2, 0.1, 0.3, 0.1, 0.2, 0.1],\n",
    "       [0.3, 0.1, 0.1, 0.2, 0.3, 0],\n",
    "       [0.1, 0.1, 0.1, 0.3, 0.2, 0.2],\n",
    "       [0.4, 0.1, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.3, 0.2, 0.1, 0.1, 0.1, 0.2],\n",
    "       [0.2, 0.2, 0.2, 0.1, 0.1, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.05, 0.05, 0.1, 0.05, 0.05]\n",
      "[0.052500000000000005, 0.025000000000000005, 0.0325, 0.027500000000000004, 0.03250000000000001, 0.030000000000000006]\n",
      "[0.024, 0.013125000000000003, 0.01675, 0.014500000000000006, 0.016750000000000004, 0.014875000000000003]\n",
      "[0.012106250000000004, 0.006581250000000001, 0.00814375, 0.007331250000000001, 0.008350000000000003, 0.007487500000000001]\n",
      "[0.0060725000000000015, 0.003291875000000001, 0.004085000000000001, 0.003643437500000001, 0.004170625000000002, 0.003736562500000001]\n"
     ]
    }
   ],
   "source": [
    "emissions = [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "pi = [.2, .1, .1, .2, .1, .1]\n",
    "frd = forward(tpm, epm, pi, emissions)\n",
    "for observation in frd:\n",
    "    print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_test(V, a, b, pi):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        V : emission matrix\n",
    "        a : tpm\n",
    "        b : epm\n",
    "        pi : initial distribution\n",
    "    \n",
    "    Returns:\n",
    "        alpha\n",
    "        \n",
    "    Citation:\n",
    "        https://datascience.stackexchange.com/questions/74126/hidden-markov-model-forward-algorithm-implementation-in-python\n",
    "    \"\"\"\n",
    "    alpha = np.zeros((len(V), len(a)))\n",
    "    \n",
    "    # alpha[0, :] = pi * b[:, V[0]]\n",
    "    for state in range(len(alpha[0])):\n",
    "        if V[0] == \"Increasing\":\n",
    "                ob = epm[state][0]\n",
    "        if V[0] == \"Decreasing\":\n",
    "                ob = epm[state][1]\n",
    "                \n",
    "        alpha[0][state] = pi[state] * ob  \n",
    "    \n",
    "    # for each observation, 1 to T\n",
    "    for t in range(1, len(V)):\n",
    "        # for each state\n",
    "        for j in range(len(a)):\n",
    "            \n",
    "            prev_state_sum = 0\n",
    "            # for each state\n",
    "            for s_prime in range(len(a)):\n",
    "                \n",
    "                if V[t] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                prev_state_sum += alpha[t - 1][s_prime] * a[s_prime][j] * b[j][idx]\n",
    "            \n",
    "            alpha[t][j] = prev_state_sum\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.05 0.05 0.1  0.05 0.05]\n",
      "[0.0525 0.025  0.0325 0.0275 0.0325 0.03  ]\n",
      "[0.024    0.013125 0.01675  0.0145   0.01675  0.014875]\n",
      "[0.01210625 0.00658125 0.00814375 0.00733125 0.00835    0.0074875 ]\n",
      "[0.0060725  0.00329188 0.004085   0.00364344 0.00417063 0.00373656]\n"
     ]
    }
   ],
   "source": [
    "frd_test = forward_test(emissions, tpm, epm, pi)\n",
    "\n",
    "for state in frd_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(frd)):\n",
    "    for state in range(len(frd[observation])):\n",
    "        # print(frd_test[observation][state], frd[observation][state])\n",
    "        assert frd_test[observation][state] == frd[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(tpm, epm, pi, observations):\n",
    "    \"\"\"probability that we will see a certain sequence of future observations, given we are in a certain state\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        backwd (int) : probability of being in a certain state\n",
    "    \"\"\"\n",
    "    # Create probability matrix forward[N,T] - initialize with 0s\n",
    "    NUM_STATES = 6\n",
    "    NUM_OBSERVATIONS = len(observations)\n",
    "    OBSERVATIONS = observations\n",
    "    beta = []\n",
    "    \n",
    "    for T in range(NUM_OBSERVATIONS):\n",
    "        row = []\n",
    "        \n",
    "        for N in range(NUM_STATES):\n",
    "            row.append(1.0)\n",
    "        \n",
    "        beta.append(row)\n",
    "    \n",
    "    # recursion\n",
    "    # for each time step from T-1 to 1 (end is exclusive)\n",
    "    for time in range(len(OBSERVATIONS) - 2, -1, -1):\n",
    "        \n",
    "        for state in range(NUM_STATES):\n",
    "            next_paths_sum = 0\n",
    "            \n",
    "            for s_prime in range(NUM_STATES):\n",
    "                # prob of getting to each next state through all possible paths \n",
    "                a = beta[time+1][s_prime]\n",
    "                \n",
    "                # the transition probability from next S to current S\n",
    "                b = tpm[state][s_prime]\n",
    "                \n",
    "                # the emission probability of emitting observation at next S\n",
    "                if OBSERVATIONS[time] == \"Increasing\":\n",
    "                    c = epm[s_prime][0]\n",
    "                if OBSERVATIONS[time] == \"Decreasing\":\n",
    "                    c = epm[s_prime][1]\n",
    "                    \n",
    "                next_paths_sum += a * b *c\n",
    "\n",
    "            beta[time][state] = next_paths_sum\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06250000000000001, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125]\n",
      "[0.25000000000000006, 0.25, 0.25, 0.25, 0.25, 0.25]\n",
      "[0.5000000000000001, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "back = backward(tpm, epm, pi, emissions)\n",
    "for state in back:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_test(observations, trans, emis, numstates):\n",
    "    backwardmatrix = numpy.zeros((len(observations), numstates))\n",
    "\n",
    "    # initialization\n",
    "    for s in range(numstates):\n",
    "        backwardmatrix[len(observations) - 1][s] = 1.0\n",
    "\n",
    "    # recursion\n",
    "    for t in range(len(observations) - 2, -1, -1):\n",
    "        \n",
    "        if observations[t] == \"Increasing\":\n",
    "            obs_index = 0\n",
    "        if observations[t] == \"Decreasing\":\n",
    "            obs_index = 1\n",
    "        \n",
    "        for s in range(numstates):\n",
    "            \n",
    "            for s2 in range(numstates):\n",
    "                backwardmatrix[t][s] += trans[s][s2] * emis[s2][obs_index] * backwardmatrix[t+1][s2]\n",
    "\n",
    "    return backwardmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "[0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "back_test = backward_test(emissions, tpm, epm, 6)\n",
    "\n",
    "for state in back_test:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in range(len(emissions)):\n",
    "    for state in range(len(back[observation])):\n",
    "        # print(back_test[observation][state], back[observation][state])\n",
    "        assert back_test[observation][state] == back[observation][state], \"(observation, state) values do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frwd_backwd(tpm, epm, init, observations):\n",
    "    \"\"\"the probability of an observation sequence occurring given the model\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        init () : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "        frwd_backwd (int) : probability of an observation sequence occurring\n",
    "    \"\"\"\n",
    "    frwd = forward(tpm, epm, pi, observations)\n",
    "    bkwd = backward(tpm, epm, pi, observations)\n",
    "\n",
    "    # matrix multiplication\n",
    "    result = [[sum(frwd*bkwd for frwd,bkwd in zip(X_row,Y_col)) for Y_col in zip(*bkwd)] for X_row in frwd]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
       " [0.060781250000000016,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001,\n",
       "  0.06078125000000001],\n",
       " [0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001,\n",
       "  0.03132812500000001],\n",
       " [0.015630859375000007,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004,\n",
       "  0.015630859375000004],\n",
       " [0.007804609375000004,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002,\n",
       "  0.007804609375000002]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frwd_backwd(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAUM WELCH ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, determine the parameters of the HMM that generated that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frwd = forward(tpm, epm, pi, emissions)\n",
    "bkwd = backward(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convergence(old_matrix, new_matrix):\n",
    "    \"\"\"returns true if matricies have converged (aka are the same), false otherwise\n",
    "    \n",
    "    Args:\n",
    "        old_matrix (array of arrays) : old matrix\n",
    "        new_matrix (array of arrays) : new matrix\n",
    "        \n",
    "    Returns:\n",
    "        converge (boolean) : represents whether the given matricies have converged or not\n",
    "        \n",
    "    \"\"\"\n",
    "    converge = True\n",
    "    for col in range(len(old_matrix)):\n",
    "        for row in range(len(old_matrix[col])):\n",
    "            if old_matrix[col][row] != new_matrix[col][row]:\n",
    "                converge = False\n",
    "    \n",
    "    return converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test check_covergence()\n",
    "\n",
    "old_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "new_matrix = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new_matrix) == True, \"method claims matricies have not converged\"\n",
    "\n",
    "new2_matrix = [[1, 2], [2, 2], [5, 6]]\n",
    "\n",
    "assert check_convergence(old_matrix, new2_matrix) == False, \"method claims matricies have converged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(tpm, epm, pi, emissions):\n",
    "    \"\"\"probability of initial parameters that generated emissions data\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # transition probabilities\n",
    "    A = np.zeros((6, 6))\n",
    "    # observation probabilities\n",
    "    B = np.ones((len(emissions) + 1, 2))\n",
    "    \n",
    "    # xi dictionary\n",
    "    xi = dict()\n",
    "    # gamma dictionary\n",
    "    gamma = dict()\n",
    "    \n",
    "    # iterate until convergence\n",
    "    # while (check_convergence(tpm, A) == False and check_convergence(epm, B) == False):\n",
    "    \n",
    "    # HOW CHECK CONVERGENCE? JUST RUN 10 TIMES\n",
    "    for i in range(10):\n",
    "        \n",
    "        # E STEP\n",
    "\n",
    "        for time in range(len(emissions)):\n",
    "    \n",
    "             # get normalization constant for time P(O|HMM)\n",
    "            normalization_const = 0\n",
    "            for state in range(6):\n",
    "                normalization_const += frwd[time][state] * bkwd[time][state]\n",
    "\n",
    "            for state_i in range(6):\n",
    "                # update gamma values for (time, state_i) in gamma dictionary\n",
    "                gamma[(time, state_i)] = (frwd[time][state_i] * bkwd[time][state_i]) / normalization_const\n",
    "\n",
    "        for time in range(len(emissions) - 1):\n",
    "\n",
    "                # get emissions index\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if emissions[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "\n",
    "                for state_i in range(6):\n",
    "\n",
    "                    for state_j in range(6):\n",
    "\n",
    "                        # update xi values for (time, state_i, state_j) in xi dictionary\n",
    "                        temp_xi = frwd[time][state_j] * tpm[state_i][state_j] * epm[state_j][idx] * bkwd[time + 1][state_j]\n",
    "                        xi[(time, state_i, state_j)] = temp_xi / normalization_const\n",
    "        \n",
    "        # M STEP\n",
    "        \n",
    "        # update alpha\n",
    "        for state_i in range(6):\n",
    "            for state_j in range(6):\n",
    "\n",
    "                nominator_sum = 0\n",
    "                denom_sum = 0\n",
    "\n",
    "                for time in range(1, len(emissions) - 1):\n",
    "                    nominator_sum += xi[(time, state_i, state_j)]\n",
    "\n",
    "                    temp_sum = 0\n",
    "                    for state_prime in range(6):\n",
    "                        temp_sum += xi[(time, state_i, state_prime)]\n",
    "\n",
    "                    denom_sum += temp_sum\n",
    "\n",
    "                A[state_i][state_j] = nominator_sum / denom_sum\n",
    "\n",
    "        # update beta\n",
    "\n",
    "        increasing_idx = 0     # tracked observation variable\n",
    "        for state in range(6):\n",
    "\n",
    "            numerator = 0\n",
    "            denom = 0\n",
    "\n",
    "            for time in range(len(emissions)):\n",
    "\n",
    "                if emissions[time] == \"Increasing\":\n",
    "                    numerator += gamma[(time, state)]\n",
    "\n",
    "                denom += gamma[(time, state)]\n",
    "\n",
    "                B[state][increasing_idx] = numerator / denom\n",
    "                B[state][1] = 1 - (numerator / denom)\n",
    "    for item in gamma:\n",
    "        print(item, gamma[item])\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0.25000000000000006\n",
      "(0, 1) 0.125\n",
      "(0, 2) 0.125\n",
      "(0, 3) 0.25\n",
      "(0, 4) 0.125\n",
      "(0, 5) 0.125\n",
      "(1, 0) 0.26250000000000007\n",
      "(1, 1) 0.125\n",
      "(1, 2) 0.16249999999999998\n",
      "(1, 3) 0.13749999999999998\n",
      "(1, 4) 0.1625\n",
      "(1, 5) 0.15\n",
      "(2, 0) 0.24000000000000002\n",
      "(2, 1) 0.13125\n",
      "(2, 2) 0.16749999999999998\n",
      "(2, 3) 0.14500000000000002\n",
      "(2, 4) 0.1675\n",
      "(2, 5) 0.14875\n",
      "(3, 0) 0.24212500000000006\n",
      "(3, 1) 0.131625\n",
      "(3, 2) 0.16287499999999994\n",
      "(3, 3) 0.14662499999999998\n",
      "(3, 4) 0.167\n",
      "(3, 5) 0.14974999999999997\n",
      "(4, 0) 0.24289999999999998\n",
      "(4, 1) 0.131675\n",
      "(4, 2) 0.1634\n",
      "(4, 3) 0.1457375\n",
      "(4, 4) 0.166825\n",
      "(4, 5) 0.1494625\n"
     ]
    }
   ],
   "source": [
    "A, B = baum_welch(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baum Welch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_test(V, a, b, pi, n_iter=100):\n",
    "    M = 6\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(tpm, epm, pi, emissions)\n",
    "        beta = backward(tpm, epm, pi, emissions)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            \n",
    "            denominator = 0\n",
    "            \n",
    "            for state in range(M):\n",
    "                # get emissions index\n",
    "                if V[t + 1] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[t + 1] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                const_a = np.dot(alpha[t][state], a)\n",
    "                const_b = b[state][idx]\n",
    "                const_c = beta[t + 1][state]\n",
    "                \n",
    "                # cant np.dot() three items, so doing it in 2 steps\n",
    "                temp = np.dot(const_a, const_b)\n",
    "                denominator += np.dot(temp, const_c)\n",
    "                \n",
    "                \n",
    "            print(denominator)\n",
    "            for i in range(M):\n",
    "                \n",
    "                numerator = 0\n",
    "                for state in range(M):\n",
    "                    # get emissions index\n",
    "                    if V[t + 1] == \"Increasing\":\n",
    "                        idx = 0\n",
    "                    if V[t + 1] == \"Decreasing\":\n",
    "                        idx = 1\n",
    "                        \n",
    "                    numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n",
    "                    \n",
    "                    xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
    "        print(xi)\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        #print(gamma)\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        # number of observations\n",
    "        K = 2\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for emission in range(K):\n",
    "            \n",
    "            for time in range(T - 1):\n",
    "                # get emissions index\n",
    "                if V[time] == \"Increasing\":\n",
    "                    idx = 0\n",
    "                if V[time] == \"Decreasing\":\n",
    "                    idx = 1\n",
    "                    \n",
    "                b_sum = 0\n",
    "                for state_i in range(M):\n",
    "                    if emission == idx:\n",
    "                        b_sum += gamma[state_i][time]\n",
    "                \n",
    "                b[state_i][emission] = b_sum\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[0.005  0.0025 0.0075 0.0025 0.005  0.0025]\n",
      " [0.0075 0.0025 0.0025 0.005  0.0075 0.    ]\n",
      " [0.0025 0.0025 0.0025 0.0075 0.005  0.005 ]\n",
      " [0.01   0.0025 0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.0075 0.005  0.0025 0.0025 0.0025 0.005 ]\n",
      " [0.005  0.005  0.005  0.0025 0.0025 0.005 ]]\n",
      "[[[0.25       0.2625     0.24       0.242125  ]\n",
      "  [0.75       0.7875     0.72       0.726375  ]\n",
      "  [0.5        0.525      0.48       0.48425   ]\n",
      "  [1.75       1.8375     1.68       1.694875  ]\n",
      "  [1.125      1.18125    1.08       1.0895625 ]\n",
      "  [2.5        2.625      2.4        2.42125   ]]\n",
      "\n",
      " [[0.125      0.125      0.13125    0.131625  ]\n",
      "  [0.5        0.5        0.525      0.5265    ]\n",
      "  [0.625      0.625      0.65625    0.658125  ]\n",
      "  [0.4375     0.4375     0.459375   0.4606875 ]\n",
      "  [0.41666667 0.41666667 0.4375     0.43875   ]\n",
      "  [       inf        inf        inf        inf]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.162875  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.375      0.4875     0.5025     0.488625  ]\n",
      "  [0.25       0.325      0.335      0.32575   ]\n",
      "  [0.5        0.65       0.67       0.6515    ]\n",
      "  [0.625      0.8125     0.8375     0.814375  ]]\n",
      "\n",
      " [[0.25       0.1375     0.145      0.146625  ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]\n",
      "  [1.5        0.825      0.87       0.87975   ]\n",
      "  [1.75       0.9625     1.015      1.026375  ]\n",
      "  [2.         1.1        1.16       1.173     ]\n",
      "  [1.25       0.6875     0.725      0.733125  ]]\n",
      "\n",
      " [[0.125      0.1625     0.1675     0.167     ]\n",
      "  [0.3125     0.40625    0.41875    0.4175    ]\n",
      "  [0.75       0.975      1.005      1.002     ]\n",
      "  [0.875      1.1375     1.1725     1.169     ]\n",
      "  [1.         1.3        1.34       1.336     ]\n",
      "  [0.625      0.8125     0.8375     0.835     ]]\n",
      "\n",
      " [[0.125      0.15       0.14875    0.14975   ]\n",
      "  [0.25       0.3        0.2975     0.2995    ]\n",
      "  [0.375      0.45       0.44625    0.44925   ]\n",
      "  [0.875      1.05       1.04125    1.04825   ]\n",
      "  [1.         1.2        1.19       1.198     ]\n",
      "  [0.625      0.75       0.74375    0.74875   ]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "[[[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]\n",
      "  [nan nan nan nan]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-b8f2ca764a78>:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  xi[i, state, t] = numerator / denominator[i][state] # DENOM RETURNS MATRIX, WHAT VALUE TO CHOOSE???\n",
      "<ipython-input-28-b8f2ca764a78>:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
      "<ipython-input-28-b8f2ca764a78>:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  b = np.divide(b, denominator.reshape((-1, 1)))\n",
      "<ipython-input-10-4eace1f230cc>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prev_paths_sum += a * b * c\n",
      "<ipython-input-16-96b97f5d25e5>:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  next_paths_sum += a * b *c\n",
      "<ipython-input-28-b8f2ca764a78>:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  numerator += alpha[t][i] * a[i][state] * b[state][idx] * beta[t + 1][state]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': array([[nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan]]),\n",
       " 'b': array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch_test(emissions, tpm, epm, pi, n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VITERBI ALGORITHM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of observed values, provide us with the sequence of states the HMM most likely has been in to generate such values sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(tpm, epm, pi, observations):\n",
    "    \"\"\"Given a sequence of observed values, provide us with the sequence of states \n",
    "        the HMM most likely has been in to generate such values sequence\n",
    "    \n",
    "    Args:\n",
    "        tpm (array of arrays) : transition probability matrix\n",
    "        epm (array of arrays) : emission probability matrix\n",
    "        pi (array) : initial distribution (probability of being in each state at the start)\n",
    "        observations (array) : array of emission symbols observed\n",
    "    \n",
    "    Returns: array of the most probable state-sequence based on the observations and HMM model\n",
    "    \"\"\"\n",
    "    \n",
    "    num_states = 6\n",
    "    states_names = ['very_low','low','moderate_low','moderate_high','high','very_high' ]\n",
    "    \n",
    "    # create path probability matrix num observations by num states\n",
    "    # initialize to 0\n",
    "    path_probability_matrix = numpy.zeros((len(observations), num_states ))\n",
    "\n",
    "    #create a path backpointer matrix backpointer[N, L + 2] to save indexes of states\n",
    "    # initialize to 0\n",
    "    path_backpointer_maxtrix = numpy.zeros((len(observations), num_states ))\n",
    "    \n",
    "    max_states = np.zeros(len(observations))\n",
    "    final_path=[]\n",
    "    final_path = ['starting' for i in range(len(observations))]\n",
    "\n",
    "    \n",
    "    #grab first observation to determine which EPM index to use\n",
    "    if observations[0] == \"Increasing\":\n",
    "        obs_index = 0\n",
    "    else:\n",
    "        obs_index = 1\n",
    "        \n",
    "    # update first row of path_probability_matrix matrix\n",
    "    # first row = probability of starting in each state * prob of seeing observation in that state\n",
    "    for s in range(num_states):\n",
    "        path_probability_matrix[0][s] = pi[s] * epm[s][obs_index]  \n",
    "    \n",
    "    for t in range(1, len(observations)):\n",
    "        for s in range(num_states):\n",
    "            \n",
    "            backpointer_probabilities = []\n",
    "            probabilities = []\n",
    "            \n",
    "            for s_prime in range(num_states):\n",
    "                \n",
    "                # prob of getting to each previous state through all possible paths\n",
    "                a = path_probability_matrix[t-1][s_prime]\n",
    "                \n",
    "                # the transition probability from previous S to current S\n",
    "                b = tpm[s_prime][s]\n",
    "                \n",
    "                # the emission probability of emitting observation at current S\n",
    "                if observations[t-1] == \"Increasing\":\n",
    "                    c = epm[s][0]\n",
    "                if observations[t-1] == \"Decreasing\":\n",
    "                    c = epm[s][1]\n",
    "                    \n",
    "                path_probability = a * b * c\n",
    "                probabilities.append(path_probability)\n",
    "        \n",
    "            # update path_probability_matrix[t,s] to MAX probability of most prob state for previous observation\n",
    "            path_probability_matrix[t][s] = max(probabilities)\n",
    "\n",
    "            # update back_pointer[t, s] to be argMax calculated of previous obs for given observation\n",
    "            path_backpointer_maxtrix[t][s] = numpy.argmax(probabilities)\n",
    "            \n",
    "    #grab end state probability and index \n",
    "    end_state_probability = max(path_probability_matrix[-1:])\n",
    "    end_state_index = numpy.argmax(path_probability_matrix[-1:])\n",
    "\n",
    "    #go backwards through backpointer\n",
    "    print('path_probability_matrix \\n', path_probability_matrix)\n",
    "    print(\"\\n before loop path_backpointer_maxtrix\", path_backpointer_maxtrix)\n",
    "    final_path[len(observations)-1] = end_state_index\n",
    "\n",
    "    for i in range(len(observations)-1, -1, -1):\n",
    "        final_path_state = path_backpointer_maxtrix[i][end_state_index]\n",
    "        final_path[i] = final_path_state\n",
    "        end_state_index = int(final_path_state)\n",
    "\n",
    "    print(final_path)\n",
    "    return(final_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1    Decreasing\n",
      "2    Increasing\n",
      "3    Decreasing\n",
      "4    Increasing\n",
      "5    Increasing\n",
      "Name: Emission, dtype: object\n",
      "path_probability_matrix \n",
      " [[1.00e-01 5.00e-02 5.00e-02 1.00e-01 5.00e-02 0.00e+00]\n",
      " [2.00e-02 5.00e-03 1.50e-02 7.50e-03 1.00e-02 0.00e+00]\n",
      " [2.00e-03 1.00e-03 3.00e-03 2.25e-03 2.00e-03 0.00e+00]\n",
      " [4.50e-04 2.00e-04 3.00e-04 4.50e-04 3.00e-04 0.00e+00]\n",
      " [9.00e-05 3.00e-05 6.75e-05 4.50e-05 4.50e-05      inf]]\n",
      "\n",
      " before loop path_backpointer_maxtrix [[0. 0. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0.]\n",
      " [3. 4. 0. 2. 2. 0.]\n",
      " [3. 4. 0. 2. 0. 1.]]\n",
      "[0.0, 3.0, 0.0, 4.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-56f2043d8916>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  path_probability = a * b * c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 3.0, 0.0, 4.0, 1.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test using the emissions \n",
    "\n",
    "#emissions_test =  [\"Increasing\", \"Increasing\", \"Increasing\", \"Decreasing\", \"Decreasing\"]\n",
    "#emissions_test = ['NaN', 'Decreasing', 'Increasing', 'Decreasing', 'Increasing', 'Increasing']\n",
    "emissions_test = df_emission['Emission']\n",
    "print(emissions_test)\n",
    "viterbi(tpm, epm, pi, emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN\n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing\n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing\n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing\n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing\n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Viterbi Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_probability_matrix \n",
      " [[1.00e-01 5.00e-02 5.00e-02 1.00e-01 5.00e-02 0.00e+00]\n",
      " [2.00e-02 5.00e-03 1.50e-02 7.50e-03 1.00e-02 0.00e+00]\n",
      " [2.00e-03 1.00e-03 3.00e-03 2.25e-03 2.00e-03 0.00e+00]\n",
      " [4.50e-04 2.00e-04 3.00e-04 4.50e-04 3.00e-04 0.00e+00]\n",
      " [9.00e-05 3.00e-05 6.75e-05 4.50e-05 4.50e-05      inf]]\n",
      "\n",
      " before loop path_backpointer_maxtrix [[0. 0. 0. 0. 0. 0.]\n",
      " [3. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0.]\n",
      " [3. 4. 0. 2. 2. 0.]\n",
      " [3. 4. 0. 2. 0. 1.]]\n",
      "[0.0, 3.0, 0.0, 4.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-56f2043d8916>:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  path_probability = a * b * c\n"
     ]
    }
   ],
   "source": [
    "# add the outcome of hidden states to the stock dataframe\n",
    "\n",
    "states_path = viterbi(tpm, epm, pi, emissions)\n",
    "\n",
    "def add_hidden_states_to_df(original_stock_df, states_path):\n",
    "    \"\"\" Add the calcuated hidden state sequence to the original stock dataframe\n",
    "    \n",
    "    Args:\n",
    "        original_stock_df (dataframe): original dataframe with stock information used in HMM\n",
    "        states_path (array): calculated state sequence using HMM\n",
    "    \n",
    "    Returns: updated stock DataFrame including the probable state-sequence based on the observations and HMM model\n",
    "    \"\"\"\n",
    "\n",
    "    states_path_df = pd.DataFrame(states_path,columns=['States_Path'])\n",
    "    states_path_df.loc[-1] = 'starting state' # add starting state because it is NaN row\n",
    "    states_path_df.index = states_path_df.index + 1  # shifting index\n",
    "    states_path_df = states_path_df.sort_index()\n",
    "    states_path_df.T\n",
    "\n",
    "    updated_stock_df = original_stock_df.copy()\n",
    "\n",
    "    updated_stock_df['Hidden_State'] = states_path_df['States_Path']\n",
    "    \n",
    "    return(updated_stock_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Yesterday Close</th>\n",
       "      <th>Close Value Difference</th>\n",
       "      <th>Emission</th>\n",
       "      <th>Hidden_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>29.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>starting state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>27.257</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.702</td>\n",
       "      <td>27.257</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>27.002</td>\n",
       "      <td>29.702</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>27.717</td>\n",
       "      <td>27.002</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>27.807</td>\n",
       "      <td>27.717</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Increasing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Close  Yesterday Close  Close Value Difference    Emission  \\\n",
       "0 1999-11-18  29.702              NaN                     NaN         NaN   \n",
       "1 1999-11-19  27.257           29.702                   -2.45  Decreasing   \n",
       "2 1999-11-22  29.702           27.257                    2.45  Increasing   \n",
       "3 1999-11-23  27.002           29.702                   -2.70  Decreasing   \n",
       "4 1999-11-24  27.717           27.002                    0.71  Increasing   \n",
       "5 1999-11-26  27.807           27.717                    0.09  Increasing   \n",
       "\n",
       "     Hidden_State  \n",
       "0  starting state  \n",
       "1               0  \n",
       "2               3  \n",
       "3               0  \n",
       "4               4  \n",
       "5               1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_stock_df = add_hidden_states_to_df(df_emission, states_path)\n",
    "updated_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_hidden_states(updated_stock_df):\n",
    "    \"\"\" Graph the hidden states by date and close price\n",
    "    \n",
    "    Args:\n",
    "        updated_stock_df (dataframe): dataframe with stock information used in HMM and determined hidden states\n",
    "    \n",
    "    Returns: Nothing, but graphs the input DF.\n",
    "    \"\"\"\n",
    "\n",
    "    dates = updated_stock_df[\"Date\"]\n",
    "    close_v = updated_stock_df[\"Close\"]\n",
    "    states = updated_stock_df[\"Hidden_State\"]\n",
    "\n",
    "    fig, axs = plt.subplots(len(updated_stock_df.Hidden_State.unique()), sharex=True, sharey=True)\n",
    "    colours = cm.rainbow(numpy.linspace(0, 1, (len(updated_stock_df.Hidden_State.unique()))))\n",
    "    for i, (ax, colour) in enumerate(zip(axs, colours)):\n",
    "        # Use fancy indexing to plot data in each state.\n",
    "        mask = states == i\n",
    "        ax.plot_date(dates[mask], close_v[mask], \".-\", c=colour)\n",
    "        ax.set_title(\"{0}th hidden state\".format(i))\n",
    "        ax.xaxis.set_minor_locator(MonthLocator())\n",
    "        ax.grid(True)\n",
    "\n",
    "    # set axis\n",
    "    plt.xlim(dates[0], dates[len(dates)-1])\n",
    "\n",
    "    # set y-axis\n",
    "    plt.ylim(0, numpy.amax(close_v) + 10)\n",
    "\n",
    "    # plt.xlim(1, 10)\n",
    "    fig.set_size_inches(15, 15)\n",
    "    seaborn.set()\n",
    "    plt.show(), states_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_hidden_states(updated_stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
